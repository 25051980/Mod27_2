{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cabec%CC%A7alho_notebook.png](cabecalho_notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Atividade Humana com PCA\n",
    "\n",
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features carregadas: (561,)\n",
      "Labels carregadas: (6, 2)\n",
      "Treino: (7352, 561) (7352, 1) (7352,)\n",
      "Teste: (2947, 561) (2947, 1) (2947,)\n"
     ]
    }
   ],
   "source": [
    "# Substitua pelo caminho correto\n",
    "base_path = \"/Users/samwalford/Downloads/UCI HAR Dataset 3/\"\n",
    "\n",
    "# Atualizando os caminhos para os arquivos\n",
    "filename_features = base_path + \"features.txt\"\n",
    "filename_labels = base_path + \"activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = base_path + \"train/subject_train.txt\"\n",
    "filename_xtrain = base_path + \"train/X_train.txt\"\n",
    "filename_ytrain = base_path + \"train/y_train.txt\"\n",
    "\n",
    "filename_subtest = base_path + \"test/subject_test.txt\"\n",
    "filename_xtest = base_path + \"test/X_test.txt\"\n",
    "filename_ytest = base_path + \"test/y_test.txt\"\n",
    "\n",
    "# Carregando os arquivos\n",
    "features = pd.read_csv(filename_features, header=None, names=['nome_var'], sep=\"#\").squeeze()\n",
    "labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "\n",
    "subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id']).squeeze()\n",
    "X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\n",
    "\n",
    "subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id']).squeeze()\n",
    "X_test = pd.read_csv(filename_xtest, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])\n",
    "\n",
    "# Exibindo informações sobre os dados carregados\n",
    "print(\"Features carregadas:\", features.shape)\n",
    "print(\"Labels carregadas:\", labels.shape)\n",
    "print(\"Treino:\", X_train.shape, y_train.shape, subject_train.shape)\n",
    "print(\"Teste:\", X_test.shape, y_test.shape, subject_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA com variáveis padronizadas\n",
    "\n",
    "Reflexão sobre a escala das variáveis:\n",
    "\n",
    "**Variáveis em métricas muito diferentes** podem interferir na análise de componentes principais. Lembra que variância é informação pra nós? Pois bem, tipicamente se há uma variável monetária como salário, vai ter uma ordem de variabilidade bem maior que número de filhos, tempo de emprego ou qualquer variável dummy. Assim, as variáveis de maior variância tendem a \"dominar\" a análise. Nesses casos é comum usar a padronização das variáveis.\n",
    "\n",
    "Faça duas análises de componentes principais para a base do HAR - com e sem padronização e compare:\n",
    "\n",
    "- A variância explicada por componente\n",
    "- A variância explicada acumulada por componente\n",
    "- A variância percentual por componente\n",
    "- A variância percentual acumulada por componente\n",
    "- Quantas componentes você escolheria, em cada caso para explicar 90% da variância?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Componentes Principais (PCA) - Com e Sem Padronização\n",
    "\n",
    "Nesta análise, realizamos duas abordagens distintas para o cálculo do PCA: uma sem padronização dos dados e outra com padronização. A seguir, comparamos os resultados em relação à variância explicada por componente, variância acumulada e a escolha de componentes para explicar 90% da variância.\n",
    "\n",
    "### 1. PCA Sem Padronização\n",
    "\n",
    "Sem padronização, os dados originais preservam suas escalas, o que pode resultar em uma dominância de variáveis com valores maiores na determinação das componentes principais.\n",
    "\n",
    "**Resultados:**\n",
    "- **Variância Explicada por Componente:** As primeiras componentes explicam a maior parte da variância, devido à influência de variáveis com escalas maiores.\n",
    "- **Variância Explicada Acumulada:** A variância acumulada cresce rapidamente nas primeiras componentes, mas é influenciada desproporcionalmente pelas variáveis dominantes.\n",
    "- **Variância Percentual por Componente:** Mostra o percentual de variância capturado por cada componente principal.\n",
    "- **Variância Percentual Acumulada:** A soma dos percentuais de variância explicada até cada componente.\n",
    "\n",
    "**Escolha de Componentes:**\n",
    "Para explicar **90% da variância**, utilizamos aproximadamente _N componentes (resultado específico baseado no cálculo)_.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. PCA Com Padronização\n",
    "\n",
    "Com padronização, todas as variáveis têm média 0 e desvio padrão 1, garantindo que cada variável contribua igualmente para o cálculo do PCA.\n",
    "\n",
    "**Resultados:**\n",
    "- **Variância Explicada por Componente:** A distribuição da variância é mais uniforme, pois nenhuma variável domina as outras.\n",
    "- **Variância Explicada Acumulada:** A variância acumulada aumenta de forma mais gradual e consistente.\n",
    "- **Variância Percentual por Componente:** Representa a contribuição percentual de cada componente.\n",
    "- **Variância Percentual Acumulada:** Fornece a soma das variâncias percentuais até cada componente.\n",
    "\n",
    "**Escolha de Componentes:**\n",
    "Para explicar **90% da variância**, utilizamos aproximadamente _M componentes (resultado específico baseado no cálculo)_.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Comparação dos Resultados\n",
    "\n",
    "| Métrica                          | Sem Padronização       | Com Padronização         |\n",
    "|----------------------------------|------------------------|--------------------------|\n",
    "| Variância Explicada (Primeira Componente) | _X% (maior)_         | _Y% (menor, mais uniforme)_ |\n",
    "| Variância Explicada Acumulada (90%)      | _N Componentes_       | _M Componentes_          |\n",
    "| Contribuição das Variáveis      | Dominância de escalas  | Contribuição igualitária |\n",
    "\n",
    "### 4. Conclusão\n",
    "\n",
    "- **Padronização Recomendada:** A padronização é preferível, pois elimina o viés causado pelas escalas das variáveis.\n",
    "- **Componentes para Explicar 90% da Variância:**\n",
    "  - Sem Padronização: _N Componentes_\n",
    "  - Com Padronização: _M Componentes_\n",
    "\n",
    "A análise com padronização resulta em uma distribuição mais uniforme da variância entre as componentes principais, enquanto a análise sem padronização tende a ser influenciada desproporcionalmente por variáveis com maior escala.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de padronização: 0.1906 segundos\n",
      "\n",
      "Resumo dos Resultados:\n",
      "- Componentes para 90% da variância (Sem Padronização): 34\n",
      "- Componentes para 90% da variância (Com Padronização): 63\n"
     ]
    }
   ],
   "source": [
    "# Função para padronizar os dados\n",
    "def padroniza(s):\n",
    "    if s.std() > 0:\n",
    "        s = (s - s.mean()) / s.std()\n",
    "    return s\n",
    "\n",
    "# Padronizando os dados de treino e teste\n",
    "start_time = time.time()\n",
    "X_train_pad = pd.DataFrame(X_train).apply(padroniza, axis=0)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Tempo de padronização: {end_time - start_time:.4f} segundos\")\n",
    "\n",
    "# PCA sem padronização\n",
    "pca_no_scaling = PCA()\n",
    "pca_no_scaling.fit(X_train)\n",
    "\n",
    "# PCA com padronização\n",
    "pca_with_scaling = PCA()\n",
    "pca_with_scaling.fit(X_train_pad)\n",
    "\n",
    "# Resumo dos resultados\n",
    "components_no_scaling = (pca_no_scaling.explained_variance_ratio_.cumsum() < 0.90).sum() + 1\n",
    "components_with_scaling = (pca_with_scaling.explained_variance_ratio_.cumsum() < 0.90).sum() + 1\n",
    "\n",
    "print(\"\\nResumo dos Resultados:\")\n",
    "print(f\"- Componentes para 90% da variância (Sem Padronização): {components_no_scaling}\")\n",
    "print(f\"- Componentes para 90% da variância (Com Padronização): {components_with_scaling}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação entre PCA com e sem Padronização\n",
    "\n",
    "A análise de componentes principais (PCA) revela diferenças importantes entre os dados com e sem padronização. \n",
    "\n",
    "- **Sem Padronização:** Apenas **34 componentes** são necessários para explicar 90% da variância. Isso ocorre porque a variância nos dados originais está altamente concentrada em algumas dimensões devido à diferença de escala entre as variáveis.\n",
    "- **Com Padronização:** São necessários **63 componentes** para alcançar 90% da variância explicada. Isso acontece porque a padronização ajusta a escala das variáveis, distribuindo melhor a variância entre elas e permitindo que mais componentes contribuam para a explicação da variabilidade total.\n",
    "\n",
    "Portanto, a padronização é essencial quando as variáveis possuem escalas diferentes, pois evita que algumas dominem a análise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça duas uma árvore de decisão com 10 componentes principais - uma com base em dados padronizados e outra sem padronizar. Utilize o ```ccp_alpha=0.001```.\n",
    "\n",
    "Compare a acurácia na base de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparação de Acurácia:\n",
      "- Acurácia Treino (Com Padronização): 0.8587\n",
      "- Acurácia Teste (Com Padronização): 0.7743\n",
      "- Acurácia Treino (Sem Padronização): 0.8912\n",
      "- Acurácia Teste (Sem Padronização): 0.8222\n"
     ]
    }
   ],
   "source": [
    "# Assumindo que X_train, X_test, y_train, y_test já estão definidos\n",
    "\n",
    "# 1. Aplicar PCA com 10 componentes\n",
    "def aplicar_pca(X_train, X_test, padronizar=False):\n",
    "    if padronizar:\n",
    "        X_train = pd.DataFrame(X_train).apply(lambda s: (s - s.mean()) / s.std(), axis=0)\n",
    "        X_test = pd.DataFrame(X_test).apply(lambda s: (s - s.mean()) / s.std(), axis=0)\n",
    "    pca = PCA(n_components=10)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "# Dados com padronização\n",
    "X_train_pca_pad, X_test_pca_pad = aplicar_pca(X_train, X_test, padronizar=True)\n",
    "\n",
    "# Dados sem padronização\n",
    "X_train_pca_no_pad, X_test_pca_no_pad = aplicar_pca(X_train, X_test, padronizar=False)\n",
    "\n",
    "# 2. Criar árvores de decisão\n",
    "tree_pad = DecisionTreeClassifier(ccp_alpha=0.001)\n",
    "tree_no_pad = DecisionTreeClassifier(ccp_alpha=0.001)\n",
    "\n",
    "# Treinar com dados padronizados\n",
    "tree_pad.fit(X_train_pca_pad, y_train)\n",
    "\n",
    "# Treinar com dados não padronizados\n",
    "tree_no_pad.fit(X_train_pca_no_pad, y_train)\n",
    "\n",
    "# 3. Avaliar acurácia\n",
    "# Dados padronizados\n",
    "y_train_pred_pad = tree_pad.predict(X_train_pca_pad)\n",
    "y_test_pred_pad = tree_pad.predict(X_test_pca_pad)\n",
    "acc_train_pad = accuracy_score(y_train, y_train_pred_pad)\n",
    "acc_test_pad = accuracy_score(y_test, y_test_pred_pad)\n",
    "\n",
    "# Dados não padronizados\n",
    "y_train_pred_no_pad = tree_no_pad.predict(X_train_pca_no_pad)\n",
    "y_test_pred_no_pad = tree_no_pad.predict(X_test_pca_no_pad)\n",
    "acc_train_no_pad = accuracy_score(y_train, y_train_pred_no_pad)\n",
    "acc_test_no_pad = accuracy_score(y_test, y_test_pred_no_pad)\n",
    "\n",
    "# 4. Comparar resultados\n",
    "print(\"Comparação de Acurácia:\")\n",
    "print(f\"- Acurácia Treino (Com Padronização): {acc_train_pad:.4f}\")\n",
    "print(f\"- Acurácia Teste (Com Padronização): {acc_test_pad:.4f}\")\n",
    "print(f\"- Acurácia Treino (Sem Padronização): {acc_train_no_pad:.4f}\")\n",
    "print(f\"- Acurácia Teste (Sem Padronização): {acc_test_no_pad:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação dos Resultados\n",
    "\n",
    "A análise dos resultados mostra que a **acurácia da árvore de decisão sem padronização** é levemente superior tanto na base de treino quanto na base de teste, indicando que os dados originais podem conter informações relevantes que se perdem ao padronizar. Por outro lado, a **acurácia na base de treino é menor nos dados padronizados**, sugerindo que a padronização ajuda a evitar overfitting ao reduzir o impacto de variáveis com escalas maiores. Apesar disso, a diferença de desempenho na base de teste é pequena, indicando que ambas as abordagens podem ser viáveis dependendo do objetivo do modelo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
